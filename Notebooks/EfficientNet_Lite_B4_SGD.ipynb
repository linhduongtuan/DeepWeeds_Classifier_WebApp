{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rPwL9bdoBNzQ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import PIL\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import timm\n",
    "import math\n",
    "import copy\n",
    "import torch\n",
    "import pickle\n",
    "import geffnet\n",
    "import logging\n",
    "import fnmatch\n",
    "import argparse\n",
    "import torchvision\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "from sklearn import metrics\n",
    "import torch.optim as optim\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from geffnet import create_model\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from collections import OrderedDict, defaultdict\n",
    "from torchvision import transforms, models, datasets\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 113041,
     "status": "ok",
     "timestamp": 1569356467203,
     "user": {
      "displayName": "APMHE15-VN APMHE15-VN",
      "photoUrl": "",
      "userId": "18025187755721220904"
     },
     "user_tz": -420
    },
    "id": "yyGpxuktB96O",
    "outputId": "7614ef22-2f41-4175-f265-79b129a33153"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 64125, 'val': 21375}\n",
      "cuda:0\n",
      "MEL Melanoma\n",
      "NV Melanocytic nevi\n",
      "BCC Basal cell carcinoma\n",
      "AK Actinic keratoses\n",
      "BKL Benign keratosis-like lesions\n",
      "DF Dermatofibroma\n",
      "VASC Vascular lesions\n",
      "SCC Squamous Cell Carcinoma\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 224, 224])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = '/home/linh/Downloads/DeepWeeds/'\n",
    "train_dir = data_dir + '/train'\n",
    "valid_dir = data_dir + '/val'\n",
    "\n",
    "# Define your transforms for the training and testing sets\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        #transforms.RandomRotation(30),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        #transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Load the datasets with ImageFolder\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "\n",
    "# Using the image datasets and the trainforms, define the data_loader\n",
    "# batch_size = 64 for EfficientNet from B0 - B3\n",
    "# batch_size = 32 for EfficientNet B4, B5\n",
    "# batch_size = 16 for EfficientNet_B6\n",
    "# batch_size = 8 for EfficientNet_B7\n",
    "# batch_size = 32 for MixNet_s\n",
    "batch_size = 16\n",
    "data_loader = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n",
    "                                             shuffle=True, num_workers=4, pin_memory = True)\n",
    "              for x in ['train', 'val']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "print(dataset_sizes)\n",
    "print(device)\n",
    "\n",
    "\"\"\"# Label mapping\n",
    "with open('/home/linh/Downloads/Derma/cat_to_name.json', 'r') as f:\n",
    "    cat_to_name = json.load(f)\"\"\"\n",
    "\n",
    "\n",
    "f = open('/home/linh/Downloads/Derma/classes.txt','r')\n",
    "cat_to_name = f.read()\n",
    "print(cat_to_name)\n",
    "f.close()\n",
    "\n",
    "### we get the class_to_index in the data_Set but what we really need is the cat_to_names  so we will create\n",
    "_ = image_datasets['train'].class_to_idx\n",
    "cat_to_name = {_[i]: i for i in list(_.keys())}\n",
    "\n",
    "    \n",
    "# Run this to test the data loader\n",
    "images, labels = next(iter(data_loader['val']))\n",
    "images.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 121421,
     "status": "ok",
     "timestamp": 1569356475598,
     "user": {
      "displayName": "APMHE15-VN APMHE15-VN",
      "photoUrl": "",
      "userId": "18025187755721220904"
     },
     "user_tz": -420
    },
    "id": "w6QP4CFPBNzg",
    "outputId": "0eb1b0c1-37d9-4538-fab8-87072bcbb2c7"
   },
   "outputs": [],
   "source": [
    "#model = EfficientNet.from_pretrained('efficientnet-b3')\n",
    "#model = timm.create_model('tf_efficientnet_b6', pretrained = True)\n",
    "#from efficientnet_pytorch import EfficientNet\n",
    "#model = EfficientNet.from_pretrained('efficientnet-b6')\n",
    "model = create_model('tf_efficientnet_lite4', pretrained=True)\n",
    "# Create classifier\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "n_classes = 9\n",
    "model.classifier = nn.Linear(model.classifier.in_features, n_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = Nadam(model.parameters(), lr=0.001)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "optimizer = optim.SGD(model.parameters(), \n",
    "                      lr=0.001,momentum=0.9,\n",
    "                      nesterov=True,\n",
    "                      weight_decay=0.0001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iPNx-TodPpVA"
   },
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=200, checkpoint = None):\n",
    "    since = time.time()\n",
    "\n",
    "    if checkpoint is None:\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        best_loss = math.inf\n",
    "        best_acc = 0.\n",
    "    else:\n",
    "        print(f'Val loss: {checkpoint[\"best_val_loss\"]}, Val accuracy: {checkpoint[\"best_val_accuracy\"]}')\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        best_loss = checkpoint['best_val_loss']\n",
    "        best_acc = checkpoint['best_val_accuracy']\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for i, (inputs, labels) in enumerate(data_loader[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                if i % 1000 == 999:\n",
    "                    print('[%d, %d] loss: %.8f' % \n",
    "                          (epoch + 1, i, running_loss / (i * inputs.size(0))))\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':                \n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            if phase == 'train':                \n",
    "                scheduler.step()\n",
    "                \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.8f} Acc: {:.8f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                print(f'New best model found!')\n",
    "                print(f'New record loss: {epoch_loss}, previous record loss: {best_loss}')\n",
    "                best_loss = epoch_loss\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                torch.save({'model_state_dict': model.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict(),\n",
    "                            'best_val_loss': best_loss,\n",
    "                            'best_val_accuracy': best_acc,\n",
    "                            'scheduler_state_dict' : scheduler.state_dict(),\n",
    "                            }, \n",
    "                            CHECK_POINT_PATH\n",
    "                            )\n",
    "                print(f'New record loss is SAVED: {epoch_loss}')\n",
    " \n",
    "        print()\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:.8f} Best val loss: {:.8f}'.format(best_acc, best_loss))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, best_loss, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 137,
     "status": "ok",
     "timestamp": 1569385104347,
     "user": {
      "displayName": "APMHE15-VN APMHE15-VN",
      "photoUrl": "",
      "userId": "18025187755721220904"
     },
     "user_tz": -420
    },
    "id": "vcXkJFOlP4NJ",
    "outputId": "2d1cd376-c190-4d2e-ac32-c61057918c8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint not found\n",
      "Epoch 0/99\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linh/.conda/envs/CV/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:82: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 999] loss: 1.47627806\n",
      "[1, 1999] loss: 1.19676352\n",
      "[1, 2999] loss: 1.05722531\n",
      "[1, 3999] loss: 0.96182261\n",
      "train Loss: 0.96084081 Acc: 0.66783626\n",
      "[1, 999] loss: 0.44940295\n",
      "val Loss: 0.44539172 Acc: 0.84842105\n",
      "New best model found!\n",
      "New record loss: 0.4453917247677407, previous record loss: inf\n",
      "New record loss is SAVED: 0.4453917247677407\n",
      "\n",
      "Epoch 1/99\n",
      "----------\n",
      "[2, 999] loss: 0.60684843\n",
      "[2, 1999] loss: 0.59155255\n",
      "[2, 2999] loss: 0.57103973\n",
      "[2, 3999] loss: 0.55484674\n",
      "train Loss: 0.55464996 Acc: 0.80792203\n",
      "[2, 999] loss: 0.31209135\n",
      "val Loss: 0.31090832 Acc: 0.89473684\n",
      "New best model found!\n",
      "New record loss: 0.31090831588966805, previous record loss: 0.4453917247677407\n",
      "New record loss is SAVED: 0.31090831588966805\n",
      "\n",
      "Epoch 2/99\n",
      "----------\n",
      "[3, 999] loss: 0.47867431\n",
      "[3, 1999] loss: 0.46214024\n",
      "[3, 2999] loss: 0.45507836\n",
      "[3, 3999] loss: 0.44661974\n",
      "train Loss: 0.44679920 Acc: 0.84611306\n",
      "[3, 999] loss: 0.23328534\n",
      "val Loss: 0.23291251 Acc: 0.91845614\n",
      "New best model found!\n",
      "New record loss: 0.23291250562388993, previous record loss: 0.31090831588966805\n",
      "New record loss is SAVED: 0.23291250562388993\n",
      "\n",
      "Epoch 3/99\n",
      "----------\n",
      "[4, 999] loss: 0.38651249\n",
      "[4, 1999] loss: 0.38967318\n",
      "[4, 2999] loss: 0.38638708\n",
      "[4, 3999] loss: 0.38063374\n",
      "train Loss: 0.38067087 Acc: 0.86895906\n",
      "[4, 999] loss: 0.18608480\n",
      "val Loss: 0.19159626 Acc: 0.93670175\n",
      "New best model found!\n",
      "New record loss: 0.19159626320091605, previous record loss: 0.23291250562388993\n",
      "New record loss is SAVED: 0.19159626320091605\n",
      "\n",
      "Epoch 4/99\n",
      "----------\n",
      "[5, 999] loss: 0.34993823\n",
      "[5, 1999] loss: 0.34334932\n",
      "[5, 2999] loss: 0.33977843\n",
      "[5, 3999] loss: 0.33536919\n",
      "train Loss: 0.33519153 Acc: 0.88531774\n",
      "[5, 999] loss: 0.15832961\n",
      "val Loss: 0.15833722 Acc: 0.94830409\n",
      "New best model found!\n",
      "New record loss: 0.15833722295538027, previous record loss: 0.19159626320091605\n",
      "New record loss is SAVED: 0.15833722295538027\n",
      "\n",
      "Epoch 5/99\n",
      "----------\n",
      "[6, 999] loss: 0.31227274\n",
      "[6, 1999] loss: 0.30560758\n",
      "[6, 2999] loss: 0.29876340\n",
      "[6, 3999] loss: 0.29734245\n",
      "train Loss: 0.29733502 Acc: 0.89880702\n",
      "[6, 999] loss: 0.14735768\n",
      "val Loss: 0.14867877 Acc: 0.95223392\n",
      "New best model found!\n",
      "New record loss: 0.14867877476222333, previous record loss: 0.15833722295538027\n",
      "New record loss is SAVED: 0.14867877476222333\n",
      "\n",
      "Epoch 6/99\n",
      "----------\n",
      "[7, 999] loss: 0.28332442\n",
      "[7, 1999] loss: 0.28109257\n",
      "[7, 2999] loss: 0.27526225\n",
      "[7, 3999] loss: 0.27183065\n",
      "train Loss: 0.27188681 Acc: 0.90719688\n",
      "[7, 999] loss: 0.12067397\n",
      "val Loss: 0.11929200 Acc: 0.96121637\n",
      "New best model found!\n",
      "New record loss: 0.11929200021007605, previous record loss: 0.14867877476222333\n",
      "New record loss is SAVED: 0.11929200021007605\n",
      "\n",
      "Epoch 7/99\n",
      "----------\n",
      "[8, 999] loss: 0.25735251\n",
      "[8, 1999] loss: 0.25337132\n",
      "[8, 2999] loss: 0.25081565\n",
      "[8, 3999] loss: 0.24878736\n",
      "train Loss: 0.24888824 Acc: 0.91563353\n",
      "[8, 999] loss: 0.10361868\n",
      "val Loss: 0.10216119 Acc: 0.96669006\n",
      "New best model found!\n",
      "New record loss: 0.10216118739545345, previous record loss: 0.11929200021007605\n",
      "New record loss is SAVED: 0.10216118739545345\n",
      "\n",
      "Epoch 8/99\n",
      "----------\n",
      "[9, 999] loss: 0.22614148\n",
      "[9, 1999] loss: 0.23189683\n",
      "[9, 2999] loss: 0.23098750\n",
      "[9, 3999] loss: 0.23062677\n",
      "train Loss: 0.23064461 Acc: 0.92034308\n",
      "[9, 999] loss: 0.09690396\n",
      "val Loss: 0.09779313 Acc: 0.96888889\n",
      "New best model found!\n",
      "New record loss: 0.09779313066514612, previous record loss: 0.10216118739545345\n",
      "New record loss is SAVED: 0.09779313066514612\n",
      "\n",
      "Epoch 9/99\n",
      "----------\n",
      "[10, 999] loss: 0.21270392\n",
      "[10, 1999] loss: 0.20915338\n",
      "[10, 2999] loss: 0.20499594\n",
      "[10, 3999] loss: 0.20329644\n",
      "train Loss: 0.20339691 Acc: 0.93116569\n",
      "[10, 999] loss: 0.08229745\n",
      "val Loss: 0.08139724 Acc: 0.97398830\n",
      "New best model found!\n",
      "New record loss: 0.08139723750060064, previous record loss: 0.09779313066514612\n",
      "New record loss is SAVED: 0.08139723750060064\n",
      "\n",
      "Epoch 10/99\n",
      "----------\n",
      "[11, 999] loss: 0.19249325\n",
      "[11, 1999] loss: 0.19865766\n",
      "[11, 2999] loss: 0.19790226\n",
      "[11, 3999] loss: 0.19706712\n",
      "train Loss: 0.19715261 Acc: 0.93330214\n",
      "[11, 999] loss: 0.07666295\n",
      "val Loss: 0.07716330 Acc: 0.97585965\n",
      "New best model found!\n",
      "New record loss: 0.07716329525001565, previous record loss: 0.08139723750060064\n",
      "New record loss is SAVED: 0.07716329525001565\n",
      "\n",
      "Epoch 11/99\n",
      "----------\n",
      "[12, 999] loss: 0.18248152\n",
      "[12, 1999] loss: 0.18461753\n",
      "[12, 2999] loss: 0.18636612\n",
      "[12, 3999] loss: 0.18836103\n",
      "train Loss: 0.18839041 Acc: 0.93624951\n",
      "[12, 999] loss: 0.08123629\n",
      "val Loss: 0.07974064 Acc: 0.97562573\n",
      "\n",
      "Epoch 12/99\n",
      "----------\n",
      "[13, 999] loss: 0.17841717\n",
      "[13, 1999] loss: 0.18112626\n",
      "[13, 2999] loss: 0.18333624\n",
      "[13, 3999] loss: 0.18458951\n",
      "train Loss: 0.18470314 Acc: 0.93724756\n",
      "[13, 999] loss: 0.07555337\n",
      "val Loss: 0.07634322 Acc: 0.97595322\n",
      "New best model found!\n",
      "New record loss: 0.0763432166556343, previous record loss: 0.07716329525001565\n",
      "New record loss is SAVED: 0.0763432166556343\n",
      "\n",
      "Epoch 13/99\n",
      "----------\n",
      "[14, 999] loss: 0.19268717\n",
      "[14, 1999] loss: 0.18702894\n",
      "[14, 2999] loss: 0.18337812\n",
      "[14, 3999] loss: 0.18275026\n",
      "train Loss: 0.18303176 Acc: 0.93815205\n",
      "[14, 999] loss: 0.08043076\n",
      "val Loss: 0.07928331 Acc: 0.97497076\n",
      "\n",
      "Epoch 14/99\n",
      "----------\n",
      "[15, 999] loss: 0.17682219\n",
      "[15, 1999] loss: 0.17559610\n",
      "[15, 2999] loss: 0.17782698\n",
      "[15, 3999] loss: 0.18040108\n",
      "train Loss: 0.18032374 Acc: 0.93843275\n",
      "[15, 999] loss: 0.07617460\n",
      "val Loss: 0.07635099 Acc: 0.97688889\n",
      "\n",
      "Epoch 15/99\n",
      "----------\n",
      "[16, 999] loss: 0.18241791\n",
      "[16, 1999] loss: 0.18014242\n",
      "[16, 2999] loss: 0.17825212\n",
      "[16, 3999] loss: 0.17842220\n",
      "train Loss: 0.17824561 Acc: 0.94016374\n",
      "[16, 999] loss: 0.07909344\n",
      "val Loss: 0.07998932 Acc: 0.97464327\n",
      "\n",
      "Epoch 16/99\n",
      "----------\n",
      "[17, 999] loss: 0.17487987\n",
      "[17, 1999] loss: 0.17975833\n",
      "[17, 2999] loss: 0.17890312\n",
      "[17, 3999] loss: 0.17914025\n",
      "train Loss: 0.17920406 Acc: 0.93957115\n",
      "[17, 999] loss: 0.07545774\n",
      "val Loss: 0.07477747 Acc: 0.97679532\n",
      "New best model found!\n",
      "New record loss: 0.0747774746097755, previous record loss: 0.0763432166556343\n",
      "New record loss is SAVED: 0.0747774746097755\n",
      "\n",
      "Epoch 17/99\n",
      "----------\n",
      "[18, 999] loss: 0.17722885\n",
      "[18, 1999] loss: 0.17006405\n",
      "[18, 2999] loss: 0.17087701\n",
      "[18, 3999] loss: 0.17132334\n",
      "train Loss: 0.17132714 Acc: 0.94253411\n",
      "[18, 999] loss: 0.08201879\n",
      "val Loss: 0.07814416 Acc: 0.97557895\n",
      "\n",
      "Epoch 18/99\n",
      "----------\n",
      "[19, 999] loss: 0.17628723\n",
      "[19, 1999] loss: 0.17114058\n",
      "[19, 2999] loss: 0.17046277\n",
      "[19, 3999] loss: 0.17116800\n",
      "train Loss: 0.17122538 Acc: 0.94279922\n",
      "[19, 999] loss: 0.07192657\n",
      "val Loss: 0.07145673 Acc: 0.97838596\n",
      "New best model found!\n",
      "New record loss: 0.07145672658678384, previous record loss: 0.0747774746097755\n",
      "New record loss is SAVED: 0.07145672658678384\n",
      "\n",
      "Epoch 19/99\n",
      "----------\n",
      "[20, 999] loss: 0.16219142\n",
      "[20, 1999] loss: 0.17001674\n",
      "[20, 2999] loss: 0.16828189\n",
      "[20, 3999] loss: 0.16725479\n",
      "train Loss: 0.16727831 Acc: 0.94334503\n",
      "[20, 999] loss: 0.07241770\n",
      "val Loss: 0.07305946 Acc: 0.97716959\n",
      "\n",
      "Epoch 20/99\n",
      "----------\n",
      "[21, 999] loss: 0.16637035\n",
      "[21, 1999] loss: 0.17217172\n",
      "[21, 2999] loss: 0.17092904\n",
      "[21, 3999] loss: 0.17013346\n",
      "train Loss: 0.17019278 Acc: 0.94270565\n",
      "[21, 999] loss: 0.07833856\n",
      "val Loss: 0.07597567 Acc: 0.97726316\n",
      "\n",
      "Epoch 21/99\n",
      "----------\n",
      "[22, 999] loss: 0.17693768\n",
      "[22, 1999] loss: 0.17451872\n",
      "[22, 2999] loss: 0.17248205\n",
      "[22, 3999] loss: 0.16909023\n",
      "train Loss: 0.16894933 Acc: 0.94272125\n",
      "[22, 999] loss: 0.07843041\n",
      "val Loss: 0.07657008 Acc: 0.97623392\n",
      "\n",
      "Epoch 22/99\n",
      "----------\n",
      "[23, 999] loss: 0.16498229\n",
      "[23, 1999] loss: 0.16829508\n",
      "[23, 2999] loss: 0.16764771\n",
      "[23, 3999] loss: 0.16723831\n",
      "train Loss: 0.16718345 Acc: 0.94400000\n",
      "[23, 999] loss: 0.07549843\n",
      "val Loss: 0.07774707 Acc: 0.97539181\n",
      "\n",
      "Epoch 23/99\n",
      "----------\n",
      "[24, 999] loss: 0.16163915\n",
      "[24, 1999] loss: 0.16517975\n",
      "[24, 2999] loss: 0.16520883\n",
      "[24, 3999] loss: 0.16689509\n",
      "train Loss: 0.16695504 Acc: 0.94342300\n",
      "[24, 999] loss: 0.07574149\n",
      "val Loss: 0.07437433 Acc: 0.97735673\n",
      "\n",
      "Epoch 24/99\n",
      "----------\n",
      "[25, 999] loss: 0.17207510\n",
      "[25, 1999] loss: 0.17009980\n",
      "[25, 2999] loss: 0.17075072\n",
      "[25, 3999] loss: 0.16952166\n",
      "train Loss: 0.16955039 Acc: 0.94309552\n",
      "[25, 999] loss: 0.07253057\n",
      "val Loss: 0.07379849 Acc: 0.97745029\n",
      "\n",
      "Epoch 25/99\n",
      "----------\n",
      "[26, 999] loss: 0.16402379\n",
      "[26, 1999] loss: 0.16646586\n",
      "[26, 2999] loss: 0.16675881\n",
      "[26, 3999] loss: 0.16597537\n",
      "train Loss: 0.16594360 Acc: 0.94417154\n",
      "[26, 999] loss: 0.07516653\n",
      "val Loss: 0.07479000 Acc: 0.97740351\n",
      "\n",
      "Epoch 26/99\n",
      "----------\n",
      "[27, 999] loss: 0.16923964\n",
      "[27, 1999] loss: 0.16995389\n",
      "[27, 2999] loss: 0.16808904\n",
      "[27, 3999] loss: 0.16722781\n",
      "train Loss: 0.16728192 Acc: 0.94261209\n",
      "[27, 999] loss: 0.07214146\n",
      "val Loss: 0.07301980 Acc: 0.97791813\n",
      "\n",
      "Epoch 27/99\n",
      "----------\n",
      "[28, 999] loss: 0.16424601\n",
      "[28, 1999] loss: 0.16791898\n",
      "[28, 2999] loss: 0.16838268\n",
      "[28, 3999] loss: 0.16819095\n",
      "train Loss: 0.16828324 Acc: 0.94334503\n",
      "[28, 999] loss: 0.06848802\n",
      "val Loss: 0.07187789 Acc: 0.97824561\n",
      "\n",
      "Epoch 28/99\n",
      "----------\n",
      "[29, 999] loss: 0.16639359\n",
      "[29, 1999] loss: 0.16311391\n",
      "[29, 2999] loss: 0.16194761\n",
      "[29, 3999] loss: 0.16246195\n",
      "train Loss: 0.16271332 Acc: 0.94598051\n",
      "[29, 999] loss: 0.07147565\n",
      "val Loss: 0.07116960 Acc: 0.97824561\n",
      "New best model found!\n",
      "New record loss: 0.07116960371307463, previous record loss: 0.07145672658678384\n",
      "New record loss is SAVED: 0.07116960371307463\n",
      "\n",
      "Epoch 29/99\n",
      "----------\n",
      "[30, 999] loss: 0.16522038\n",
      "[30, 1999] loss: 0.16571072\n",
      "[30, 2999] loss: 0.16451948\n",
      "[30, 3999] loss: 0.16562595\n",
      "train Loss: 0.16551745 Acc: 0.94474854\n",
      "[30, 999] loss: 0.07340975\n",
      "val Loss: 0.07141070 Acc: 0.97730994\n",
      "\n",
      "Epoch 30/99\n",
      "----------\n",
      "[31, 999] loss: 0.17059939\n",
      "[31, 1999] loss: 0.16963844\n",
      "[31, 2999] loss: 0.16853777\n",
      "[31, 3999] loss: 0.16843584\n",
      "train Loss: 0.16838867 Acc: 0.94343860\n",
      "[31, 999] loss: 0.07201621\n",
      "val Loss: 0.07072634 Acc: 0.97749708\n",
      "New best model found!\n",
      "New record loss: 0.07072633721640235, previous record loss: 0.07116960371307463\n",
      "New record loss is SAVED: 0.07072633721640235\n",
      "\n",
      "Epoch 31/99\n",
      "----------\n",
      "[32, 999] loss: 0.15875463\n",
      "[32, 1999] loss: 0.16372267\n",
      "[32, 2999] loss: 0.16374801\n",
      "[32, 3999] loss: 0.16309610\n",
      "train Loss: 0.16332078 Acc: 0.94465497\n",
      "[32, 999] loss: 0.07078068\n",
      "val Loss: 0.07149967 Acc: 0.97726316\n",
      "\n",
      "Epoch 32/99\n",
      "----------\n",
      "[33, 999] loss: 0.17249415\n",
      "[33, 1999] loss: 0.16824409\n",
      "[33, 2999] loss: 0.16752294\n",
      "[33, 3999] loss: 0.16397362\n",
      "train Loss: 0.16397974 Acc: 0.94521637\n",
      "[33, 999] loss: 0.07886562\n",
      "val Loss: 0.07540343 Acc: 0.97679532\n",
      "\n",
      "Epoch 33/99\n",
      "----------\n",
      "[34, 999] loss: 0.17186547\n",
      "[34, 1999] loss: 0.16943500\n",
      "[34, 2999] loss: 0.16736434\n",
      "[34, 3999] loss: 0.16582305\n",
      "train Loss: 0.16592325 Acc: 0.94414035\n",
      "[34, 999] loss: 0.07166261\n",
      "val Loss: 0.07241043 Acc: 0.97745029\n",
      "\n",
      "Epoch 34/99\n",
      "----------\n",
      "[35, 999] loss: 0.17201891\n",
      "[35, 1999] loss: 0.16831260\n",
      "[35, 2999] loss: 0.16951828\n",
      "[35, 3999] loss: 0.16982692\n",
      "train Loss: 0.16976680 Acc: 0.94303314\n",
      "[35, 999] loss: 0.07672013\n",
      "val Loss: 0.07714119 Acc: 0.97651462\n",
      "\n",
      "Epoch 35/99\n",
      "----------\n",
      "[36, 999] loss: 0.16480807\n",
      "[36, 1999] loss: 0.16426047\n",
      "[36, 2999] loss: 0.16409383\n",
      "[36, 3999] loss: 0.16493713\n",
      "train Loss: 0.16487251 Acc: 0.94398441\n",
      "[36, 999] loss: 0.07450287\n",
      "val Loss: 0.07368163 Acc: 0.97787135\n",
      "\n",
      "Epoch 36/99\n",
      "----------\n",
      "[37, 999] loss: 0.16565746\n",
      "[37, 1999] loss: 0.16969883\n",
      "[37, 2999] loss: 0.16875928\n",
      "[37, 3999] loss: 0.16789462\n",
      "train Loss: 0.16788548 Acc: 0.94356335\n",
      "[37, 999] loss: 0.07053971\n",
      "val Loss: 0.07017571 Acc: 0.97819883\n",
      "New best model found!\n",
      "New record loss: 0.07017571393505, previous record loss: 0.07072633721640235\n",
      "New record loss is SAVED: 0.07017571393505\n",
      "\n",
      "Epoch 37/99\n",
      "----------\n",
      "[38, 999] loss: 0.17244363\n",
      "[38, 1999] loss: 0.16519858\n",
      "[38, 2999] loss: 0.16673760\n",
      "[38, 3999] loss: 0.16518328\n",
      "train Loss: 0.16538438 Acc: 0.94418713\n",
      "[38, 999] loss: 0.06822665\n",
      "val Loss: 0.06963941 Acc: 0.97847953\n",
      "New best model found!\n",
      "New record loss: 0.06963940523946059, previous record loss: 0.07017571393505\n",
      "New record loss is SAVED: 0.06963940523946059\n",
      "\n",
      "Epoch 38/99\n",
      "----------\n",
      "[39, 999] loss: 0.16242621\n",
      "[39, 1999] loss: 0.16555480\n",
      "[39, 2999] loss: 0.16727581\n",
      "[39, 3999] loss: 0.16856181\n",
      "train Loss: 0.16863020 Acc: 0.94247173\n",
      "[39, 999] loss: 0.07348878\n",
      "val Loss: 0.07542127 Acc: 0.97656140\n",
      "\n",
      "Epoch 39/99\n",
      "----------\n",
      "[40, 999] loss: 0.16416924\n",
      "[40, 1999] loss: 0.16650420\n",
      "[40, 2999] loss: 0.16564302\n",
      "[40, 3999] loss: 0.16503635\n",
      "train Loss: 0.16507248 Acc: 0.94495127\n",
      "[40, 999] loss: 0.07349790\n",
      "val Loss: 0.07424418 Acc: 0.97702924\n",
      "\n",
      "Epoch 40/99\n",
      "----------\n",
      "[41, 999] loss: 0.16420237\n",
      "[41, 1999] loss: 0.16708381\n",
      "[41, 2999] loss: 0.16926955\n",
      "[41, 3999] loss: 0.16674721\n",
      "train Loss: 0.16683005 Acc: 0.94334503\n",
      "[41, 999] loss: 0.07476001\n",
      "val Loss: 0.07277057 Acc: 0.97829240\n",
      "\n",
      "Epoch 41/99\n",
      "----------\n",
      "[42, 999] loss: 0.16153116\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuDNN error: CUDNN_STATUS_MAPPING_ERROR",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-72c1ca0d3ab8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m                                                  \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                                                  \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                                                  \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;31m# torch.load(CHECK_POINT_PATH)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                                                  ) \n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-ea24fe031cd0>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs, checkpoint)\u001b[0m\n\u001b[1;32m     52\u001b[0m                     \u001b[0;31m# backward + optimize only if in training phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m                         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/CV/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/CV/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuDNN error: CUDNN_STATUS_MAPPING_ERROR"
     ]
    }
   ],
   "source": [
    "CHECK_POINT_PATH = '/home/linh/Downloads/DeepWeeds/weights/EfficientNet_Lite4_NS_SGD.pth'\n",
    "try:\n",
    "    checkpoint = torch.load(CHECK_POINT_PATH)\n",
    "    print(\"checkpoint loaded\")\n",
    "except:\n",
    "    checkpoint = None\n",
    "    print(\"checkpoint not found\")\n",
    "if checkpoint == None:\n",
    "    CHECK_POINT_PATH = CHECK_POINT_PATH\n",
    "model, best_val_loss, best_val_acc = train_model(model,\n",
    "                                                 criterion,\n",
    "                                                 optimizer,\n",
    "                                                 scheduler,\n",
    "                                                 num_epochs = 100,\n",
    "                                                 checkpoint = None # torch.load(CHECK_POINT_PATH)\n",
    "                                                 ) \n",
    "                                                \n",
    "torch.save({'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'best_val_loss': best_val_loss,\n",
    "            'best_val_accuracy': best_val_acc,\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            }, CHECK_POINT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "EfficientNet_B6.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
