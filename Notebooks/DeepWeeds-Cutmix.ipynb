{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 40178,
     "status": "ok",
     "timestamp": 1588213047201,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "rPwL9bdoBNzQ",
    "outputId": "553f83f0-cbf1-48d5-a184-4f4c8ff055ac"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sls\n",
    "import PIL\n",
    "import sys\n",
    "import glob\n",
    "import json\n",
    "import time\n",
    "import timm\n",
    "import math\n",
    "import copy\n",
    "import torch\n",
    "import pickle\n",
    "import logging\n",
    "import fnmatch\n",
    "import argparse\n",
    "import itertools\n",
    "import torchvision\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import albumentations\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "import scikitplot as skplt\n",
    "from sklearn import metrics\n",
    "import torch.optim as optim\n",
    "from timm import create_model\n",
    "from datetime import datetime\n",
    "from timm.data.loader import *\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from torch.optim import lr_scheduler\n",
    "#from pytorch_metric_learning import loss\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from timm.models.layers.activations import *\n",
    "from timm.utils import accuracy, AverageMeter\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "#from timm.utils import ApexScaler, NativeScaler\n",
    "from timm.models.registry import register_model\n",
    "from timm.models.helpers import load_pretrained\n",
    "from collections import OrderedDict, defaultdict\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from timm.models.resnet import resnet26d, resnet50d\n",
    "from torchvision import transforms, models, datasets\n",
    "from timm.models.helpers import build_model_with_cfg\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "#from timm.models.layers import DropPath, to_2tuple, trunc_normal_\n",
    "from timm.data import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
    "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy\n",
    "from timm.models.efficientnet import efficientnet_b0, efficientnet_b1, efficientnet_b2, efficientnet_b3\n",
    "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score, roc_curve, auc, roc_auc_score\n",
    "#from timm.data import Dataset, DatasetTar, RealLabelsImagenet, create_loader, Mixup, FastCollateMixup, AugMixDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 179460,
     "status": "ok",
     "timestamp": 1588213186502,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "yyGpxuktB96O",
    "outputId": "584ea32f-dbe1-4465-8e60-e0f4e5c96a6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1035185', '1035195', '1035931', '1036216', '4474169', '4475140', '5755079', '7508714', '9364935']\n",
      "{'train': 6434, 'val': 6434, 'test': 6434}\n",
      "cuda\n",
      "{0: '1035185', 1: '1035195', 2: '1035931', 3: '1036216', 4: '4474169', 5: '4475140', 6: '5755079', 7: '7508714', 8: '9364935'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 3, 224, 224])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_dir = '/home/linh/Downloads/'\n",
    "data_dir = os.path.join(root_dir, 'DeepWeeds')\n",
    "save_weights = os.path.join(data_dir, 'weights')\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "batch_size = 200\n",
    "# Batch_size (48 or 50 for EfficientNet-B0, img_size=320, cuda=0 or cuda=1) \n",
    "# Batch_size (64 or 68 for EfficientNet-B1, img_size=240, cuda=0 or cuda=1)\n",
    "num_epochs = 120\n",
    "lr = 0.01\n",
    "beta = 1\n",
    "step_size = 30\n",
    "img_size = 224\n",
    "test_size = int((256 / 224) * img_size)\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "num_workers = 4\n",
    "# Define your transforms for the training and testing sets\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomRotation(30),\n",
    "        transforms.RandomResizedCrop(img_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(0.3, 0.3, 0.3),\n",
    "        #RandAugment(),\n",
    "        #ImageNetPolicy(),\n",
    "        #Cutout(size=16),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std),\n",
    "        transforms.RandomErasing(),\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(test_size),\n",
    "        transforms.CenterCrop(img_size),\n",
    "        transforms.ColorJitter(0.5, 0.5, 0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(test_size),\n",
    "        transforms.CenterCrop(img_size),\n",
    "        transforms.ColorJitter(0.5, 0.5, 0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Load the datasets with ImageFolder\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val', 'test']}\n",
    "class_names = image_datasets['train'].classes\n",
    "num_classes = len(class_names)\n",
    "data_loader = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n",
    "                                             shuffle=True, num_workers=num_workers, pin_memory = True)\n",
    "              for x in ['train', 'val', 'test']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}\n",
    "\n",
    "print(class_names)\n",
    "print(dataset_sizes)\n",
    "print(device)\n",
    "\n",
    "### we get the class_to_index in the data_Set but what we really need is the cat_to_names  so we will create\n",
    "_ = image_datasets['val'].class_to_idx\n",
    "cat_to_name = {_[i]: i for i in list(_.keys())}\n",
    "print(cat_to_name)\n",
    "    \n",
    "# Run this to test the data loader\n",
    "images, labels = next(iter(data_loader['val']))\n",
    "images.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 603
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 226470,
     "status": "ok",
     "timestamp": 1588213233519,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "N350JAHpu8c3",
    "outputId": "96a2d095-f78f-4ca5-eb0c-c5390e367831"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def showimage(data_loader, number_images, cat_to_name):\\n    dataiter = iter(data_loader)\\n    images, labels = dataiter.next()\\n    images = images.numpy() # convert images to numpy for display\\n    # plot the images in the batch, along with the corresponding labels\\n    fig = plt.figure(figsize=(number_images, 4))\\n    for idx in np.arange(number_images):\\n        ax = fig.add_subplot(2, number_images/2, idx+1, xticks=[], yticks=[])\\n        img = np.transpose(images[idx])\\n        plt.imshow(img)\\n        ax.set_title(cat_to_name[labels.tolist()[idx]])\\n        \\n#### to show some  images\\nshowimage(data_loader['test'], 20, cat_to_name)\\n\\nmean = np.array([0.485, 0.456, 0.406]) \\nstd = np.array([0.229, 0.224, 0.225])\\ndef imshow(inp, title):\\n    inp = inp.numpy().transpose((1, 2, 0))\\n    inp = std * inp + mean\\n    inp = np.clip(inp, 0, 1)\\n    plt.imshow(inp)\\n    plt.title(title)\\n    plt.show\\n    \\ninputs, classes = next(iter(data_loader['val']))\\nout = torchvision.utils.make_grid(inputs)\\nimshow(out, title=[class_names[x] for x in classes])\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def showimage(data_loader, number_images, cat_to_name):\n",
    "    dataiter = iter(data_loader)\n",
    "    images, labels = dataiter.next()\n",
    "    images = images.numpy() # convert images to numpy for display\n",
    "    # plot the images in the batch, along with the corresponding labels\n",
    "    fig = plt.figure(figsize=(number_images, 4))\n",
    "    for idx in np.arange(number_images):\n",
    "        ax = fig.add_subplot(2, number_images/2, idx+1, xticks=[], yticks=[])\n",
    "        img = np.transpose(images[idx])\n",
    "        plt.imshow(img)\n",
    "        ax.set_title(cat_to_name[labels.tolist()[idx]])\n",
    "        \n",
    "#### to show some  images\n",
    "showimage(data_loader['test'], 20, cat_to_name)\n",
    "\n",
    "mean = np.array([0.485, 0.456, 0.406]) \n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "def imshow(inp, title):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    plt.title(title)\n",
    "    plt.show\n",
    "    \n",
    "inputs, classes = next(iter(data_loader['val']))\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "imshow(out, title=[class_names[x] for x in classes])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 226461,
     "status": "ok",
     "timestamp": 1588213233520,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "L9jdFtBjSAE6",
    "outputId": "f0f393c5-4369-422c-9aef-fc290ccc941d"
   },
   "outputs": [],
   "source": [
    "#model = models.resnet50(pretrained=True)\n",
    "#model = timm.create_model('resnet50', pretrained=True)\n",
    "#model = timm.create_model('efficientnet_b0', pretrained=True, drop_rate=0.2)\n",
    "#model = timm.create_model('efficientnet_b1', num_classes=num_classes+1,pretrained=True, drop_rate=0.2, drop_path_rate=0.2, drop_connect_rate=0.2)\n",
    "model = timm.create_model('inception_v3', num_classes=num_classes+1,\n",
    "                          pretrained=True, #drop_rate=0.4, drop_path_rate=0.4, drop_connect_rate=0.4\n",
    "                         )\n",
    "#model.fc #show fully connected layer for ResNet family\n",
    "#model.classifier #show the classifier layer (fully connected layer) for EfficientNets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 226454,
     "status": "ok",
     "timestamp": 1588213233520,
     "user": {
      "displayName": "DUONG TUAN LINH",
      "photoUrl": "",
      "userId": "10844282398210252241"
     },
     "user_tz": -420
    },
    "id": "w6QP4CFPBNzg",
    "outputId": "6beb0600-5fdf-4ae6-a216-40c32a13bb9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of parameters of the model is: 21806058\n"
     ]
    }
   ],
   "source": [
    "# Create classifier\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "# define `classifier` for ResNet\n",
    "# Otherwise, define `fc` for EfficientNet family \n",
    "#because the definition of the full connection/classifier of 2 CNN families is differnt\n",
    "fc = nn.Sequential(OrderedDict([('fc1', nn.Linear(2048, 1000, bias=True)),\n",
    "\t\t\t\t\t\t\t     ('BN1', nn.BatchNorm2d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
    "\t\t\t\t\t\t\t\t ('dropout1', nn.Dropout(0.7)),\n",
    "                                 ('fc2', nn.Linear(1000, 512)),\n",
    "\t\t\t\t\t\t\t\t ('BN2', nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
    "\t\t\t\t\t\t\t\t ('swish1', Swish()),\n",
    "\t\t\t\t\t\t\t\t ('dropout2', nn.Dropout(0.5)),\n",
    "\t\t\t\t\t\t\t\t ('fc3', nn.Linear(512, 128)),\n",
    "\t\t\t\t\t\t\t\t ('BN3', nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
    "\t\t\t\t\t\t\t     ('swish2', Swish()),\n",
    "\t\t\t\t\t\t\t\t ('fc4', nn.Linear(128, num_classes+1)),\n",
    "\t\t\t\t\t\t\t\t #('output', nn.Softmax(dim=1))\n",
    "\t\t\t\t\t\t\t ]))\n",
    "# connect base model (EfficientNet_B0) with modified classifier layer\n",
    "#model.fc = fc\n",
    "criterion = LabelSmoothingCrossEntropy()\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = Nadam(model.parameters(), lr=0.001)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, nesterov=True, weight_decay=0.0001)\n",
    "#optimizer = sls.Sls(model.parameters())\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=0.1)\n",
    "#lr = lambda x: (((1 + math.cos(x * math.pi / num_epochs)) / 2) ** 1) * 0.9\n",
    "#scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr)\n",
    "#scheduler_warmup = GradualWarmupScheduler(optimizer, multiplier=1, total_epoch=5, after_scheduler=scheduler)\n",
    "model.to(device)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "count = count_parameters(model)\n",
    "print(\"The number of parameters of the model is:\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/clovaai/CutMix-PyTorch\n",
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iPNx-TodPpVA"
   },
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "\n",
    "def train_model(model, criterion, optimizer, \n",
    "                scheduler, \n",
    "                num_epochs=200, checkpoint = None):\n",
    "    since = time.time()\n",
    "\n",
    "    if checkpoint is None:\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        best_loss = math.inf\n",
    "        best_acc = 0.\n",
    "    else:\n",
    "        print(f'Val loss: {checkpoint[\"best_val_loss\"]}, Val accuracy: {checkpoint[\"best_val_accuracy\"]}')\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        #scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        best_loss = checkpoint['best_val_loss']\n",
    "        best_acc = checkpoint['best_val_accuracy']\n",
    "    # Tensorboard summary\n",
    "    writer = SummaryWriter()\n",
    "    start_time_per_epoch = time.time()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch + 1, num_epochs)) #(epoch, num_epochs -1)\n",
    "        print('-' * 20)\n",
    "        \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                #scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for i, (inputs, labels) in enumerate(data_loader[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "                # establish function for SLS optimization\n",
    "                #def closure():\n",
    "                #    probs = F.log_softmax(model(inputs), dim=1)\n",
    "                #    loss = F.nll_loss(probs, labels, reduction=\"sum\")\n",
    "                    \n",
    "                #    return loss\n",
    "                \n",
    "                if i % 1000 == 999:\n",
    "                    print('[%d, %d] loss: %.8f' % \n",
    "                          (epoch + 1, i, running_loss / (i * inputs.size(0))))\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        #optimizer.step(closure)\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            if phase == 'train':                \n",
    "                scheduler.step()\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.8f} Acc: {:.8f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            # Record training loss and accuracy for each phase\n",
    "            if phase == 'train':\n",
    "                writer.add_scalar('Train/Loss', epoch_loss, epoch)\n",
    "                writer.add_scalar('Train/Accuracy', epoch_acc, epoch)\n",
    "                writer.flush()\n",
    "            else:\n",
    "                writer.add_scalar('Valid/Loss', epoch_loss, epoch)\n",
    "                writer.add_scalar('Valid/Accuracy', epoch_acc, epoch)\n",
    "                writer.flush()\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                print(f'New best model found!')\n",
    "                print(f'New record loss: {epoch_loss}, previous record loss: {best_loss}')\n",
    "                best_loss = epoch_loss\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                torch.save({'model_state_dict': model.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict(),\n",
    "                            'best_val_loss': best_loss,\n",
    "                            'best_val_accuracy': best_acc,\n",
    "                            'scheduler_state_dict' : scheduler.state_dict(),\n",
    "                            }, \n",
    "                            CHECK_POINT_PATH\n",
    "                            )\n",
    "                print(f'New record loss is SAVED: {epoch_loss}')\n",
    "            \"\"\"if phase == 'val' and epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "                iteration_change_loss = 0\n",
    "\n",
    "            if iteration_change_loss == 10: #choose a number of epochs for patience\n",
    "                print('Early stopping after {0} iterations without the decrease of the val loss'. format(iteration_change_loss))\n",
    "                break\"\"\"\n",
    "             \n",
    "                \n",
    "        end_time_per_epoch = (time.time() - start_time_per_epoch)\n",
    "        print('Time for training the last epoch: {:.0f}m {:.0f}s'.format(\n",
    "        end_time_per_epoch // 60, end_time_per_epoch % 60))\n",
    "        \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Total training time complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:.8f} Best val loss: {:.8f}'.format(best_acc, best_loss))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, best_loss, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-c32f8cc92aa32ddd\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-c32f8cc92aa32ddd\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir runs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "vcXkJFOlP4NJ",
    "outputId": "e47fadb8-c292-4051-8a56-bbdc5868abe8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs\n",
      "Wall time: 6.44 µs\n",
      "checkpoint not found\n",
      "Epoch 1/120\n",
      "--------------------\n",
      "train Loss: 1.73564022 Acc: 0.49440472\n",
      "val Loss: 1.33223341 Acc: 0.65091700\n",
      "New best model found!\n",
      "New record loss: 1.3322334051280427, previous record loss: inf\n",
      "New record loss is SAVED: 1.3322334051280427\n",
      "Time for training the last epoch: 0m 30s\n",
      "Epoch 2/120\n",
      "--------------------\n",
      "train Loss: 1.10501415 Acc: 0.75163196\n",
      "val Loss: 0.88405395 Acc: 0.86757849\n",
      "New best model found!\n",
      "New record loss: 0.884053952619086, previous record loss: 1.3322334051280427\n",
      "New record loss is SAVED: 0.884053952619086\n",
      "Time for training the last epoch: 0m 57s\n",
      "Epoch 3/120\n",
      "--------------------\n",
      "train Loss: 0.93590271 Acc: 0.82794529\n",
      "val Loss: 0.77542667 Acc: 0.90223811\n",
      "New best model found!\n",
      "New record loss: 0.7754266662074425, previous record loss: 0.884053952619086\n",
      "New record loss is SAVED: 0.7754266662074425\n",
      "Time for training the last epoch: 1m 24s\n",
      "Epoch 4/120\n",
      "--------------------\n",
      "train Loss: 0.86650571 Acc: 0.85918558\n",
      "val Loss: 0.78315006 Acc: 0.90861051\n",
      "Time for training the last epoch: 1m 51s\n",
      "Epoch 5/120\n",
      "--------------------\n",
      "train Loss: 0.83026260 Acc: 0.87177495\n",
      "val Loss: 0.65676316 Acc: 0.95306186\n",
      "New best model found!\n",
      "New record loss: 0.6567631633080864, previous record loss: 0.7754266662074425\n",
      "New record loss is SAVED: 0.6567631633080864\n",
      "Time for training the last epoch: 2m 19s\n",
      "Epoch 6/120\n",
      "--------------------\n",
      "train Loss: 0.79656248 Acc: 0.88887162\n",
      "val Loss: 0.62254304 Acc: 0.96813802\n",
      "New best model found!\n",
      "New record loss: 0.6225430416623591, previous record loss: 0.6567631633080864\n",
      "New record loss is SAVED: 0.6225430416623591\n",
      "Time for training the last epoch: 2m 45s\n",
      "Epoch 7/120\n",
      "--------------------\n",
      "train Loss: 0.76853510 Acc: 0.89508859\n",
      "val Loss: 0.60909937 Acc: 0.97109108\n",
      "New best model found!\n",
      "New record loss: 0.6090993712620592, previous record loss: 0.6225430416623591\n",
      "New record loss is SAVED: 0.6090993712620592\n",
      "Time for training the last epoch: 3m 12s\n",
      "Epoch 8/120\n",
      "--------------------\n",
      "train Loss: 0.75019802 Acc: 0.90146099\n",
      "val Loss: 0.59356435 Acc: 0.97668635\n",
      "New best model found!\n",
      "New record loss: 0.5935643500966021, previous record loss: 0.6090993712620592\n",
      "New record loss is SAVED: 0.5935643500966021\n",
      "Time for training the last epoch: 3m 38s\n",
      "Epoch 9/120\n",
      "--------------------\n",
      "train Loss: 0.74238755 Acc: 0.90674541\n",
      "val Loss: 0.60403612 Acc: 0.96689462\n",
      "Time for training the last epoch: 4m 4s\n",
      "Epoch 10/120\n",
      "--------------------\n",
      "train Loss: 0.73185199 Acc: 0.90969848\n",
      "val Loss: 0.61677670 Acc: 0.96269817\n",
      "Time for training the last epoch: 4m 29s\n",
      "Epoch 11/120\n",
      "--------------------\n",
      "train Loss: 0.71636636 Acc: 0.91544918\n",
      "val Loss: 0.64447945 Acc: 0.94777743\n",
      "Time for training the last epoch: 4m 55s\n",
      "Epoch 12/120\n",
      "--------------------\n",
      "train Loss: 0.70635379 Acc: 0.91902394\n",
      "val Loss: 0.78870952 Acc: 0.88327634\n",
      "Time for training the last epoch: 5m 21s\n",
      "Epoch 13/120\n",
      "--------------------\n",
      "train Loss: 0.72255128 Acc: 0.90907678\n",
      "val Loss: 0.55457520 Acc: 0.98570096\n",
      "New best model found!\n",
      "New record loss: 0.5545751997540372, previous record loss: 0.5935643500966021\n",
      "New record loss is SAVED: 0.5545751997540372\n",
      "Time for training the last epoch: 5m 52s\n",
      "Epoch 14/120\n",
      "--------------------\n",
      "train Loss: 0.69277098 Acc: 0.92803855\n",
      "val Loss: 0.63471442 Acc: 0.95275101\n",
      "Time for training the last epoch: 6m 19s\n",
      "Epoch 15/120\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "CHECK_POINT_PATH = '/home/linh/Downloads/DeepWeeds/weights/Inception_V3_SGD.pth'\n",
    "\n",
    "try:\n",
    "    checkpoint = torch.load(CHECK_POINT_PATH)\n",
    "\n",
    "    print(\"checkpoint loaded\")\n",
    "except:\n",
    "    checkpoint = None\n",
    "    print(\"checkpoint not found\")\n",
    "if checkpoint == None:\n",
    "    CHECK_POINT_PATH = CHECK_POINT_PATH\n",
    "model, best_val_loss, best_val_acc = train_model(model,\n",
    "                                                 criterion,\n",
    "                                                 optimizer,\n",
    "                                                 scheduler,\n",
    "                                                 num_epochs = num_epochs,\n",
    "                                                 checkpoint = None #torch.load(CHECK_POINT_PATH)\n",
    "                                                 ) \n",
    "                                                \n",
    "torch.save({'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'best_val_loss': best_val_loss,\n",
    "            'best_val_accuracy': best_val_acc,\n",
    "            #'scheduler_state_dict': scheduler.state_dict(),\n",
    "            }, CHECK_POINT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.suam(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "def plot_roc_curve(fpr, tpr):\n",
    "    plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=2, label='ROC curve (area = %0.4f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")  \n",
    "    plt.show()\n",
    "    \n",
    "def plt_roc(test_y, probas_y, plot_micro=False, plot_macro=False):\n",
    "    assert isinstance(test_y, list) and isinstance(probas_y, list), 'the type of input must be list'\n",
    "    \n",
    "    skplt.metrics.plot_roc(test_y, probas_y, plot_micro=plot_micro,plot_macro=plot_macro) #, figsize=(10, 8))\n",
    "    #plt.savefig(add_prefix(args.prefix, 'roc_auc_curve.png'))\n",
    "    plt.show()\n",
    "    #plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "def compute_validate_meter(model, data_loader): # best_model_path,\n",
    "    \n",
    "    since = time.time()\n",
    "\n",
    "    CHECK_POINT_PATH = '/home/linh/Downloads/DeepWeeds/weights/EfficientNet_B4_224_SLS.pth'\n",
    "\n",
    "    try:\n",
    "        checkpoint = torch.load(CHECK_POINT_PATH)\n",
    "        print(\"checkpoint loaded\")\n",
    "    except:\n",
    "        checkpoint = None\n",
    "        print(\"checkpoint not found\")\n",
    "\n",
    "    def load_model(best_model_path):                                \n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        best_loss = checkpoint['best_val_loss']\n",
    "        best_acc = checkpoint['best_val_accuracy']\n",
    "    load_model(CHECK_POINT_PATH)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    pred_y = list()\n",
    "    test_y = list()\n",
    "    probas_y = list()   \n",
    "    with torch.no_grad():\n",
    "        #pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n",
    "        for data, target in data_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            data, target = Variable(data), Variable(target)\n",
    "            output = model(data)\n",
    "            probas_y.extend(output.data.cpu().numpy().tolist())\n",
    "            pred_y.extend(output.data.cpu().max(1, keepdim=True)[1].numpy().flatten().tolist())\n",
    "            test_y.extend(target.data.cpu().numpy().flatten().tolist())\n",
    "        # compute the confusion matrix\n",
    "        confusion = confusion_matrix(test_y, pred_y)\n",
    "        # plot the confusion matrix\n",
    "        plot_labels = ['Chinee Apple', 'Lantana', 'Negative','Parkinsonia', 'Parthenium', 'Prickly acacia', 'Rubber vine', 'Siam weed', 'Snake weed']\n",
    "     \n",
    "        plot_confusion_matrix(confusion, plot_labels)\n",
    "        #plot_confusion_matrix(confusion, classes=val_loader.dataset.classes,title='Confusion matrix')\n",
    "        # print Recall, Precision, F1-score, Accuracy\n",
    "        report = classification_report(test_y, pred_y, digits=4)\n",
    "        print(report)\n",
    "        plt_roc(test_y, probas_y)\n",
    "        \n",
    "    time_elapsed = time.time() - since\n",
    "\n",
    "    print('Inference completes in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "count = count_parameters(model)\n",
    "print(count)\n",
    "\n",
    "#best_model_path = '/home/linh/Downloads/TB/weights/EfficientNet_B1_240.pth'\n",
    "\n",
    "compute_validate_meter(model, data_loader['test_0']) #best_model_path,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['label'] = np.argmax(tst_preds, axis=1)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('/home/linh/Downloads/leaf/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('/home/linh/Downloads/leaf/sample_submission.csv')\n",
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Covid-19_EfficientNet_B0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
